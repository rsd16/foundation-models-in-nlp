{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGIz6l2u17C3"
   },
   "source": [
    "## Homework 2, FMNLP Fall 2023\n",
    "### You have ten days for this assignment, please submit as PDF(File>Print>Save as PDF). 100 points total.\n",
    "\n",
    "---\n",
    "If you have any further questions or concerns, contact the TA via email:\n",
    "baghbani.hamed@gmail.com or baghbani.hamed@ut.ac.ir\n",
    "#####Telegram: @HBaghbani\n",
    "\n",
    "***LINK: *paste your link here****\n",
    "\n",
    "---\n",
    "\n",
    "#### IMPORTANT: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this homework!\n",
    "***LINK:*** https://colab.research.google.com/drive/1ZyzWqyAsrX0qp-x6CAAHmSyYHphImdSD?usp=sharing\n",
    "\n",
    "---\n",
    "##### *How to submit this problem set:*\n",
    "- Write all the answers in this Colab notebook. Once you are finished, generate a PDF via (File -> Print -> Save as PDF) and upload it to Elearn (elearn.ut.ac.ir).\n",
    "  \n",
    "- **Important:** check your PDF before you submit to Elearn to make sure it exported correctly. If Colab gets confused about your syntax, it will sometimes terminate the PDF creation routine early.\n",
    "\n",
    "- **Important:** on Elearn, please make sure that you tag each page with the corresponding question(s). This makes it significantly easier for our graders to grade submissions, especially with the long outputs of many of these cells. We will take off points for submissions that are not tagged.\n",
    "\n",
    "- When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. One handy way to do this is by clicking `Runtime -> Run All` in the notebook menu.\n",
    "\n",
    "---\n",
    "\n",
    "##### *Academic honesty*\n",
    "\n",
    "- We will audit the Colab notebooks from a set number of students, chosen at random. The audits will check that the code you wrote actually generates the answers in your PDF. If you turn in correct answers on your PDF without code that actually generates those answers, we will consider this a serious case of cheating. See the course page for honesty policies.\n",
    "\n",
    "- We will also run automatic checks of Colab notebooks for plagiarism. Copying code from others is also considered a serious case of cheating.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2dYC4HbZL-j"
   },
   "source": [
    "# Part 1: Annotation\n",
    "\n",
    "In this homework, you will first collect a labeled dataset of 360 **Persian sentences**  for a text classification task of your choice.\n",
    "You can do this in teams of size three.\n",
    "(Note that you can build teams of one or two as well but then you need to ask two or one other annotators to help you.)\n",
    "The process will include:\n",
    "\n",
    "1. *Data collection*: Collect 360 Persian sentences from any source you find interesting (e.g., literature, Tweets, news articles, reviews, etc.)\n",
    "\n",
    "2.  *Task design*: Come up with a binary (i.e., only two labels) sentence-level classification task that you would like to perform on your sentences. Be creative, and make sure your task isn't too easy (e.g., perhaps the labels have some degree of subjectivity to them, or the task is otherwise complex for humans). Write up annotator guidelines/instructions on how you would like people to label your data\n",
    "\n",
    "3. On your dataset, every example must be annotated by three persons. In order to get everything done on time, you need to complete the following steps:\n",
    "\n",
    ">  * Build annotation guideline\n",
    "*   Annotate the data (e.g., a spreadsheet or Google form)\n",
    "*   Collect the labeled data from each of the three annotators.\n",
    "*   Sanity check the data for basic cleanliness (are all examples annotated? are all labels allowable ones?)\n",
    "\n",
    "4. Collect feedback from all the team members about the task including annotation time and obstacles encountered (e.g., maybe your guidelines were confusing! or maybe some sentences were particularly hard to annotate!)\n",
    "\n",
    "5. Calculate and report inter-annotator agreement.\n",
    "\n",
    "6. Aggregate output from three annotators to create final dataset.\n",
    "\n",
    "7. Perform NLP experiments on your new dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Heui1z3IjZh_"
   },
   "source": [
    "## Question 1.1 (10 points):\n",
    "Describe the source of your unlabeled data, why you chose it, and what kind of sentence selection process you used (if any) to choose 120 sentences for annotation. Also briefly describe the text classification task that you will be collecting labels for in the next section.\n",
    "\n",
    "### *WRITE YOUR ANSWER HERE* ###\n",
    "\n",
    "Since I consider myself an avid gamer, after multiple discussions with my teammates, we decided to use the comments and review/comment section of the [Hayoola website](https://hayoola.com/#!/home). This website is in Persian. In this website the game developers publish their developed games online. People pay real money to buy the games, and get to play it. This website can be considered an Iranian version of [Steam website](https://store.steampowered.com/).\n",
    "\n",
    "Some people, after finishing a game, write a review/comment on that game, or leave a comment about it. Their points on how the games were good, or bad, or chould have been better, can be useful. We wondered that this type of dataset would never see the light of the day, since, Iranian games are kind of in minority in our country, and not that many gamers play them (compared the foriegn games being played in our country). So, we seized this opportunity as to introduce a new source or dataset of Persian text, other than Instagram, Twitter or regular news websites.\n",
    "\n",
    "We crawled the said website using a Python source code, and collected reviews/comments and comments of the people on games. We selected only Persian text, since, there were some Finglish comments as well. We tried to be diverse, inclusive of most genres and games. Our gathered reviews/comments are of any size, whether long or short, or even an essay-like comprising of multiple sentences. Sentiment-wise, we tried our absolute hardest to collect as balanced dataset as we could. Overall, our collected samples can be considered a good representative and also an introduction to this website for further data collection process.\n",
    "\n",
    "After we collected our dataset and our decisions on what sentences to use and what to ignore, we decided to label all sentences independently, without knowing others' label. We used binary labeling system: 1 means the overall sentiment of the review/comment is positive; 0 means the overall sentiment is negative. Each of us considered the review/comment as a whole, and decided on the overall intent of the user.\n",
    "\n",
    "One positive note on our gathered dataset can be attributed to the fact that the reviews/comments in our dataset vary in size. Some reviews/comments are really long, comprising of multiple sentences, in which, the user has tried their best to describe the positive and negative aspects of the game. Some reviews/comments are short and in them, the user has just stated their enjoyment or disappointment of the game. We had this goal in our mind that we like to fine-tune the pre-trained model on a diverse set of reviews/comments, both in sentiment and size of the review/comment. When we give the model really long reviews/comments, we like the model to understand the whole intent of the user, rather than fixating on just few short sentences. In this way, we can be sure that if the model has performed well, it was because it really understood the intent of the review/comment, rather than just fixating on some few keywords. Thus, the model has to be general and robust at the same time, and try its best to look at a review/comment as a whole and understand the user's intent, rather than memorization. Because, some reviews/comments may use bad points or strong criticism against a specific game, but they mean well and have enjoyed the game a lot, and want the game to be more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EynpTLydj7IM"
   },
   "source": [
    "## Question 1.2 (25 points):\n",
    "Copy the annotation guidelines that you provided to your classmates below. We expect that these guidelines will be very detailed (and as such could be fairly long). You must include:\n",
    "\n",
    "> *   The two categories for your binary classification problem, including the exact strings you want annotators to use while labeling.\n",
    "*   Descriptions of the categories and what they mean.\n",
    "*   Representative examples of each category (i.e., sentences from outside your dataset that you have manually labeled to give annotators an idea of how to perform the task)\n",
    "*   A discussion of of tricky corner cases, and criteria to help the annotator decide them. If you look at the data and think about how an annotator could do the task, you will likely find a bunch of these!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### *COPY YOUR ANNOTATION GUIDELINES HERE.* Please format them nicely so it's easy for us to read / grade :)###\n",
    "\n",
    "The overall guidelines I had on my mind when labeling the reviews/comments and also what I told my teammates are as follow:\n",
    "* I only considered the author's intent as to only be positive or negative, ignoring other labels such as neutral.\n",
    "* A review/comment might contain negative wording or sentences. I considered the overall intent of the author. For example, a review/comment might contain some criticism, but, overall the author has enjoyed the game a lot and the criticism is just for letting the game developers know how to improve the game. Overall, I determined the overall sentiment of the review/comment, whether it leans towards a positive or negative evaluation of the game, not letting minor details or criticism points have more weight.\n",
    "* I mostly considered the user's subjective opinion, and the overall emotions they felt during or after they wrote a review/comment; and also, I considered objective side of the review/comment, what the user has felt and meant to tell. I balanced between these two, and labeled the review/comment accordingly based upon what I thought of the review/comment, and overall experience the user has felt.\n",
    "* I did not consider the number of likes or dislikes a review has gotten. I only read the text.\n",
    "* I familiarized myself with the specific context of the game being reviewed. This helped me understand the user's perspective and the elements they focused on.\n",
    "* I excluded objective information such as game specifications, facts, or technical details that do not express the user's sentiment. As I said above, I only focused on the emotional content of the reviews/comments.\n",
    "* I paid attention to any key indicators of sentiment including language tone, specific adjectives, adverbs, and emotional expressions that suggest positivity or negativity.\n",
    "* It is again important to mention that we all reviewed all the reviews/comments once, and labeled it independently without letting the other teammates know of our labels.\n",
    "* And last but not least, I ensured that my annotations are not influenced by my personal opinions. I stayed objective and focused on the user's perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YiyCp-ZNRj1"
   },
   "outputs": [],
   "source": [
    "# the piece of code we wrote to collect and gather reviews/comments from Hayoola website:\n",
    "\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://hayoola.com/games#!/search/0\")\n",
    "\n",
    "# some util functions to makes our code cleaner & more reliable:\n",
    "def get_name() -> str:\n",
    "    return driver.find_element(By.CLASS_NAME, \"game-title\").get_attribute(\"innerText\")\n",
    "\n",
    "def get_score() -> float:\n",
    "    return float(driver.find_element(By.CLASS_NAME, \"game-rating-value\").get_attribute(\"innerText\").split()[0])\n",
    "\n",
    "def get_rating() -> float:\n",
    "    return float(driver.find_element(By.CLASS_NAME, \"game-comment-count\").get_attribute(\"innerText\").split()[0])\n",
    "\n",
    "def get_reviews() -> list:\n",
    "    reviews = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    for review in driver.find_elements(By.CLASS_NAME, \"game-review\"):\n",
    "        date = review.find_element(By.CLASS_NAME, \"game-review-date\").get_attribute(\"innerText\")\n",
    "\n",
    "        rate = (review.find_element(By.CLASS_NAME, \"game-rating-value\").get_attribute(\"innerText\").split()[0])\n",
    "        text = review.find_element(By.CLASS_NAME, \"limitted-height-el\").get_attribute(\"innerText\")\n",
    "\n",
    "        votes = tuple()\n",
    "\n",
    "        try:\n",
    "            votes = (review.find_element(By.CLASS_NAME, \"game-review-vote-details\").get_attribute(\"innerText\").split())\n",
    "            votes = tuple(map(int, filter(lambda x: str(x).isdigit(), votes)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        reviews.append({\"date\": date, \"rate\": float(rate), \"text\": text, \"votes\": votes})\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# the following loop extracts only the game links:\n",
    "\n",
    "game_links = dict()\n",
    "\n",
    "for p in range(4):\n",
    "    WebDriverWait(driver, 1)\n",
    "\n",
    "    game_links[f\"page_{p + 1}\"] = [x.get_attribute(\"href\") for x in driver.find_elements(By.CLASS_NAME, \"game-card\")]\n",
    "\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, f\"//button[contains(text(), '{p + 2}')]\").click()\n",
    "        time.sleep(5)\n",
    "        WebDriverWait(driver, 2)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "# the following loop extracts data from each game's page:\n",
    "\n",
    "games = []\n",
    "\n",
    "for link in set(sum(game_links.values(), [])):\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        WebDriverWait(driver, timeout=2)\n",
    "\n",
    "        games.append({\"link\": link, \"name\": get_name(), \"score\": get_score(), \"ratings\": get_rating(), \"reviews\": get_reviews()})\n",
    "\n",
    "        print(\"Total Reviews:\", sum(map(lambda x: len(x[\"reviews\"]), games)))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"DONE\")\n",
    "        break\n",
    "\n",
    "with open(\"games.json\", \"w\") as f:\n",
    "    json.dump(games, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"gameLinks.json\", \"w\") as f:\n",
    "    json.dump(game_links, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1cPcFHQHDQH"
   },
   "outputs": [],
   "source": [
    "# the piece of code i used to read the original data we collected:\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"games.json\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "reviews_text = [review[\"text\"] for item in data for review in item[\"reviews\"]]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "\n",
    "df[\"text\"] = reviews_text\n",
    "print(df.head())\n",
    "\n",
    "#df.to_csv(\"reviews with no labels.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1CGhDXHC8VZ"
   },
   "outputs": [],
   "source": [
    "# the piece of code i utilized for labelling:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"reviews with no labels.csv\")\n",
    "\n",
    "df[\"label\"] = -1666\n",
    "print(df.head())\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df.loc[i, \"label\"] == -1666:\n",
    "        print(df.loc[i, \"text\"])\n",
    "\n",
    "        df.loc[i, \"label\"] = int(input(\"\\nenter your label: \"))\n",
    "\n",
    "#df.to_csv(\"1.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "935duWappc-o"
   },
   "source": [
    "## Question 1.3 (5 points):\n",
    "Write down the names and emails of the two classmates who will be annotating your data below. Once they are finished annotating, create two .csv files (annotator1.csv and annotator2.csv) that contains each annotator's labels. The file should have two columns with headers **text** and **label**, respectively. You will include these files in an email to the instructors account when you're finished with this homework.\n",
    "\n",
    "*The tweets.csv file provided as an example in Part 2 below uses the same format.*\n",
    "\n",
    "### *WRITE CLASSMATE 1 NAME/EMAIL HERE:* ### Mohammad Mehdi Mohajeri (mehdimohajeri78@gmail.com)\n",
    "### *WRITE CLASSMATE 2 NAME/EMAIL HERE:* ### Mahyar Riazati (mr.riazati1999@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcIMegO_uPRK"
   },
   "source": [
    "## Question 1.4 (10 points):\n",
    "After both annotators have finished labeling the 120 sentences you gave them, ask them for feedback about your task and the provided annotation guidelines. If you were to collect more labeled data for this task in the future, what would you change from your current setup? Why? Please include a summary of annotator feedback (with specific examples that they found challenging to label) in your answer.\n",
    "\n",
    "### *WRITE ANSWER HERE* ###\n",
    "\n",
    "After each of us finished labeling the reviews/comments, we talked about the process and experience each of us had while labeling. Some reviews/comments had conflicting points in the whole paragraph or sentences, but the overall intent was positive. However, we were on the fence as to whether label these types of reviews/comments as positive or negative. Those who supported the idea of the review/comment being positive, claimed that the constructive criticism should not be considered negative; the most important thing is that the user has enjoyed the game. However, on the other side, those who supported the negative labeling, pointed to the multiple issues a user for example has had, and this fact has rendered the users' experience down; thus, labeling the review/comment as negative, even though the user said the game is good. We discussed this topic for multiple sessions and we heard the opposing opinions and feedbacks.\n",
    "\n",
    "As said previously, we considered both objective and emotional aspects of a review. We balanced between these two, and labeled the review/comment accordingly, based upon what we think of the review/comment and overall experience.\n",
    "\n",
    "Another issue we all encountered was that there could have been another label, such as neutral. Some reviews/comments were not solely about reviewing the game or saying one's opinion about the game. Rather, they were about thanking the developers of a game, asking questions, or bringing topics and issues which were not relevant to the game at all. In these types of reviews/comments, we considered the tone of the user, whether they tried to be genuine or sarcastic, and we labeled accordingly.\n",
    "\n",
    "And finally, if we were to collect more labeled data for this task in the future, we would consider collecting reviews/comments from other similar websites as well. Iranian gamers who play Iranian games are not that many, however, from this experience that we had with Hayoola website, we believe any similar can be a great source of reviews/comments. Some gamers tend to review a game, or complain or praise it in great detail. Thus, the websites like this can be great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ltte0Z-vD0u"
   },
   "source": [
    "## Question 1.5 (10 points):\n",
    "Now, compute the inter-annotator agreement between your two annotators. Upload both .csv files to your Colab session (click the folder icon in the sidebar to the left of the screen). In the code cell below, read the data from the two files and compute both the raw agreement (% of examples for which both annotators agreed on the label) and the [Cohen's Kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa). Feel free to use implementations in existing libraries (e.g., [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html)). After you're done, paste the numbers in the text cell that follows your code.\n",
    "\n",
    "*If you're curious, Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UD7yvkwgy82S",
    "outputId": "a7ff0855-2c6f-401f-ae52-7c6fa649cb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHEN'S KAPPA: 0.41968\n",
      "RAW AGREEMENT: 76.88%\n"
     ]
    }
   ],
   "source": [
    "### WRITE CODE TO LOAD ANNOTATIONS AND\n",
    "### COMPUTE AGREEMENT + COHEN'S KAPPA HERE!\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "y_mahyar = pd.read_csv(\"mahyar.csv\")[\"label\"]\n",
    "y_emad = pd.read_csv(\"emad.csv\")[\"label\"] # we call Mohammad Mehdi, Emad .)))\n",
    "\n",
    "cohen_kappa = cohen_kappa_score(y_mahyar, y_emad)\n",
    "print(f\"COHEN'S KAPPA: {cohen_kappa:.5f}\")\n",
    "\n",
    "raw_agreement = sum(1 for annotation1, annotation2 in zip(y_mahyar, y_emad) if annotation1 == annotation2) / len(y_mahyar) * 100\n",
    "print(f\"RAW AGREEMENT: {raw_agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qd7Xq4SKzF5U"
   },
   "source": [
    "###*RAW AGREEMENT*: 76.88%\n",
    "###*COHEN'S KAPPA*: 0.41968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2-1LkRHze5N"
   },
   "source": [
    "## Question 1.6 (10 points):\n",
    "To form your final dataset, you need to *aggregate* the annotations from both annotators (i.e., for cases where they disagree, you need to choose a single label). Use any method you like other than random label selection to perform this aggregation (e.g., have the two annotators discuss each disagreement and come to consensus, or choose the label you agree with the most). Upload your final dataset to the Colab session (in the same format as the other two files) as final_dataset.csv. Remember to include this file in your final submit to us!\n",
    "\n",
    "### *DESCRIBE YOUR AGGREGATION STRATEGY HERE* ###\n",
    "\n",
    "After we discussed about how we performed labeling for reviews/comments, I had two approaches to decide between labels: relabeling my label for the reviews/comments based upon my teammates' votes; or do a majority-voting strategy, in which, the label with most occurence would be the final label.\n",
    "\n",
    "I have written the code for both parts. However, the approach I chose was the first one. After some discussions and hearing my teammates' opinions and seeing their labeling strategy and also labels, I decided to relabel the reviews/comments, with having their mindset alongisde mine as well. For this, I sat down and checked any review/comment which were labeled differently by us, and we did not label them the same. I read those reviews/comments again and considered the labels, my teammates had assigned to them. Then, I decided a suitable label for each review/comment. Sometimes, I stood my ground and used the label i previously gave to that review/comment. And sometimes, I used one of teammate's label for that review. I put myself in my teammates' shoes and reviewed the review/comment from their perspective. I chose this approach as my main.\n",
    "\n",
    "Another approach, which I also implemented below, is majority-voting between votes of all three of us. I also considered this approach before my final decision on which approach to choose, since, I reasoned that maybe it is better to choose the label which has more votes on it. This approach can be fair and objective sometimes, but it cannot be more accurate and better than the approach above, at least in my opinion. Since, some reviews/comments needed thorough inspection. Therefore, I did not choose this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PpFaLPSFNwN"
   },
   "outputs": [],
   "source": [
    "# the piece of code i utilized for my main approach:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_emad = pd.read_csv(\"emad.csv\")\n",
    "df_mahyar = pd.read_csv(\"mahyar.csv\")\n",
    "df_1 = pd.read_csv(\"1.csv\")\n",
    "\n",
    "df = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "\n",
    "df[\"text\"] = df_1[\"text\"]\n",
    "df[\"label\"] = -1666\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    if df_emad.loc[i, \"label\"] + df_mahyar.loc[i, \"label\"] + df_1.loc[i, \"label\"] == 0 or \\\n",
    "    df_emad.loc[i, \"label\"] + df_mahyar.loc[i, \"label\"] + df_1.loc[i, \"label\"] == 3:\n",
    "        df.loc[i, \"label\"] = df_1.loc[i, \"label\"]\n",
    "    else:\n",
    "        print(df.loc[i, \"text\"])\n",
    "\n",
    "        print(\"\\nMAHYAR: \", df_mahyar.loc[i, \"label\"])\n",
    "        print(\"EMAD: \", df_emad.loc[i, \"label\"])\n",
    "        print(\"1: \", df_1.loc[i, \"label\"])\n",
    "\n",
    "        df.loc[i, \"label\"] = int(input(\"\\nenter your label: \"))\n",
    "\n",
    "display(df)\n",
    "\n",
    "#df.to_csv(\"final_data.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "K7JqYTIMzzQx",
    "outputId": "619864e1-b28a-478a-e36f-188ea9574d8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a0958a7e-1cb0-43de-992f-89165bf1e913\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بازی خوبی بود ولی چون چک پوینت کم داشت و با وج...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بازی بسیار زیبا در عین حال با موسیقی های 8 بیت...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلام بازی خیلی خوبیه هر چند یه سری ایراد داره ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>واقعا دمتون گرم با این بازی خیلی عالیه</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>بازی قشنگ بود اما تورو جدتون دیالوگ ها رو کتاب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>این بازی ایرانی به شدت توصیه می شود. نقاط قوت:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>خوب بود ولی تو یه مرحله گیر کرد راه نرفت</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>بازی در بیشتر مورد هایی که من می خواستم خوب بو...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>بینظیر بهترین بازی که برای تاریخ کشورمون هست ا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>خیلی خوبه وقتی بازی میکنی انگار واقعا داری میج...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0958a7e-1cb0-43de-992f-89165bf1e913')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a0958a7e-1cb0-43de-992f-89165bf1e913 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a0958a7e-1cb0-43de-992f-89165bf1e913');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-04f7ccfa-945d-4dcf-b82e-28db749916fa\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04f7ccfa-945d-4dcf-b82e-28db749916fa')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-04f7ccfa-945d-4dcf-b82e-28db749916fa button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    بازی خوبی بود ولی چون چک پوینت کم داشت و با وج...      0\n",
       "1    بازی بسیار زیبا در عین حال با موسیقی های 8 بیت...      1\n",
       "2    سلام بازی خیلی خوبیه هر چند یه سری ایراد داره ...      1\n",
       "3               واقعا دمتون گرم با این بازی خیلی عالیه      1\n",
       "4    بازی قشنگ بود اما تورو جدتون دیالوگ ها رو کتاب...      0\n",
       "..                                                 ...    ...\n",
       "380  این بازی ایرانی به شدت توصیه می شود. نقاط قوت:...      1\n",
       "381           خوب بود ولی تو یه مرحله گیر کرد راه نرفت      1\n",
       "382  بازی در بیشتر مورد هایی که من می خواستم خوب بو...      1\n",
       "383  بینظیر بهترین بازی که برای تاریخ کشورمون هست ا...      1\n",
       "384  خیلی خوبه وقتی بازی میکنی انگار واقعا داری میج...      1\n",
       "\n",
       "[385 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# another approach to aggregate annotations from all annotators:\n",
    "\n",
    "df_emad = pd.read_csv(\"emad.csv\")\n",
    "df_mahyar = pd.read_csv(\"mahyar.csv\")\n",
    "df_1 = pd.read_csv(\"1.csv\")\n",
    "\n",
    "final_data = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "\n",
    "final_data[\"text\"] = df_1[\"text\"]\n",
    "final_data[\"label_1\"] = df_1[\"label\"]\n",
    "final_data[\"label_emad\"] = df_emad[\"label\"]\n",
    "final_data[\"label_mahyar\"] = df_mahyar[\"label\"]\n",
    "\n",
    "# inspired by https://stackoverflow.com/a/55749310\n",
    "final_data[\"label\"] = final_data.mode(axis=1)\n",
    "\n",
    "final_data.drop(columns=[\"label_1\", \"label_emad\", \"label_mahyar\"], inplace=True)\n",
    "\n",
    "display(final_data)\n",
    "\n",
    "#final_data.to_csv(\"final_data.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d23zfO_ALKeB"
   },
   "source": [
    "# Part 2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N25dvF4jvYoy"
   },
   "source": [
    "Now we'll move onto fine-tuning  pretrained language models specifically on your dataset. This part of the homework is meant to be an introduction to the HuggingFace library, and it contains code that will potentially be useful for your final projects. Since we're dealing with large models, the first step is to change to a GPU runtime.\n",
    "\n",
    "## Adding a hardware accelerator\n",
    "\n",
    "Please go to the menu and add a GPU as follows:\n",
    "\n",
    "`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n",
    "\n",
    "Run the following cell to confirm that the GPU is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edOh9ooiIW1B",
    "outputId": "836ab56d-b62d-45b8-aec9-b863cab957eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: Tesla T4, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Confirm that the GPU is detected\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvH7xx9LnMC"
   },
   "source": [
    "## Installing Hugging Face's Transformers library\n",
    "We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n",
    "\n",
    "Run the following cell to install Hugging Face's Transformers library and download a sample data file called tweets.csv that contains tweets about airlines along with a negative, neutral, or positive sentiment rating. Note that you will be asked to link with your Google Drive account to download some of these files. If you're concerned about security risks (there have not been any issues in previous semesters), feel free to make a new Google account and use it for this homework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtqS2e5fxpqa",
    "outputId": "df4e09a4-c69a-49f8-ea06-a44c68d26153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n",
      "success!\n",
      "helper file downloaded! (helpers.py)\n",
      "sample tweets downloaded! (tweets.csv)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "print('success!')\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Download helper functions file\n",
    "helper_file = drive.CreateFile({'id': '16HW-z9Y1tM3gZ_vFpJAuwUDohz91Aac-'})\n",
    "helper_file.GetContentFile('helpers.py')\n",
    "print('helper file downloaded! (helpers.py)')\n",
    "\n",
    "# Download sample file of tweets\n",
    "data_file = drive.CreateFile({'id': '1QcoAmjOYRtsMX7njjQTYooIbJHPc6Ese'})\n",
    "data_file.GetContentFile('tweets.csv')\n",
    "print('sample tweets downloaded! (tweets.csv)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8XIL7wPovVX"
   },
   "source": [
    "The cell below imports some helper functions we wrote to demonstrate the task on the sample tweet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Taseb33Sovg0"
   },
   "outputs": [],
   "source": [
    "from helpers import tokenize_and_format, flat_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKc0xYh-MAbc"
   },
   "source": [
    "# Part 1: Data Prep and Model Specifications\n",
    "\n",
    "Upload your data using the file explorer to the left. We have provided a function below to tokenize and format your data as BERT requires. Make sure that your csv file, titled final_data.csv, has one column \"text\" and another column \"labels\" containing integers.\n",
    "\n",
    "If you run the cell below without modifications, it will run on the tweets.csv example data we have provided. It imports some helper functions we wrote to demonstrate the task on the sample tweet dataset. You should first run all of the following cells with tweets.csv just to see how everything works. Then, once you understand the whole preprocessing / fine-tuning process, change the csv in the below cell to your final_data.csv file, add any extra preprocessing code you wish, and then run the cells again on your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "79460ad755494fa785bf176e6f0d6f9b",
      "44cc931cb4344e3fad48cb3fd7db8bbe",
      "2659e1f1ef3442baa5beeb86b8027587",
      "53680c03cf86480184017b6b090f85df",
      "7039b328993b42449fd817ad078415d2",
      "fbfb65254be341a1809459aaaffec5f1",
      "5768b842fd86457d854ac88ff334933d",
      "f66d9a518d724a998fb8435208cb4837",
      "43d8d32e27f348f3bf941ea94ea3e91e",
      "47db893e385142b68a5ef615e6b1aa0f",
      "b00b01e9b53c4993bd2cd232109b7ca2",
      "b6ee7836a1ed45688c3090451b2711d3",
      "0d500c622d6f4594a1d80889504d6d09",
      "61230637ed1b4fd98a494791416029a9",
      "43e12cdf3c9b480baeea10403319ce86",
      "190c8e95a7844c8492729bbf0197be17",
      "01d1fe918573417ca15ffdf3464a9360",
      "83705bfc34134a3ea0e825420bc6c7ad",
      "51c65e5ca4924d97bdfb92e28436a538",
      "d426ba3f665346dd8b67d62b856cde49",
      "ae5224b5e173463892870ffc69cd2c58",
      "8454ba6b1afc49df870acf75c24c9d1c",
      "c7a1fa1ca8324b33aede90a754c19d16",
      "f3d7c078b27b4704b218d59e161c85f9",
      "b6007f26921543f9be04c3654c949597",
      "9ae06fb985c84e5ea447e92da8ebb501",
      "fc971c2cf8af4283a8ce330bf27cae75",
      "c908cbe920aa48e4bafc31da35f4f2cc",
      "71c7f61706094afd9feb2f7eef43fa53",
      "72571fd7d911419e95de25d7cee605cf",
      "530458bd90844459899615a517070cb1",
      "ee2bf4dd8fa94dd5834ad815644bb6b6",
      "4e0efdf992ff4db49d8964e1ac05d129",
      "6355e1a49a034b37a0dd3ebebb4b2ffd",
      "1d4850d0f00a45a98c3f2ecedce94654",
      "6aff4307521d451193b7d9e10c0f3b4e",
      "837d3915d27e4bca9c8d262981121780",
      "5b1a53374cb445a89f6b7dd622d834d6",
      "37f67a74d0c0478c9c47a65b70afcc44",
      "107d352250ea4018892b3dfc29bf4ac4",
      "fb03dc01540e4e22972da416e07e539d",
      "97c7028605234b979237a3c6487c1bc8",
      "40d5fc4582b14c16bfc1af217d77595d",
      "bd99d54bca6b44f99372221f1ace4115"
     ]
    },
    "id": "YGhkeLQlNNr8",
    "outputId": "e8ab6393-d00c-46b7-8fb1-47a7b4027b26"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79460ad755494fa785bf176e6f0d6f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ee7836a1ed45688c3090451b2711d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a1fa1ca8324b33aede90a754c19d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6355e1a49a034b37a0dd3ebebb4b2ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  لذت بردم و دارم میبرم واقعا بی نظیر بود و همچنان دارم لذت میبرم ازش\n",
      "Token IDs: tensor([  101,  1294, 29822, 29817,  1271, 17149, 15394, 22192,  1298,  1278,\n",
      "        25573, 17149, 22192,  1295, 24830, 29816, 17149, 22192,  1298, 25573,\n",
      "        29834, 29830, 25573,  1271, 24830,  1296, 29829, 24830, 17149,  1271,\n",
      "        29836, 15394,  1298,  1297, 22192, 29840, 15915, 18511,  1278, 25573,\n",
      "        17149, 22192,  1294, 29822, 29817,  1295, 24830, 29816, 17149, 22192,\n",
      "         1270, 29823, 29825,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "from helpers import tokenize_and_format, flat_accuracy\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('final_data.csv')\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "texts = df.text.values\n",
    "labels = df.label.values\n",
    "\n",
    "### tokenize_and_format() is a helper function provided in helpers.py ###\n",
    "input_ids, attention_masks = tokenize_and_format(texts)\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3D-CzQEUXYz"
   },
   "source": [
    "## Create train/test/validation splits\n",
    "\n",
    "Here we split your dataset into 3 parts: a training set, a validation set, and a testing set. Each item in your dataset will be a 3-tuple containing an input_id tensor, an attention_mask tensor, and a label tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGgeZ3M0UWs0"
   },
   "outputs": [],
   "source": [
    "\n",
    "total = len(df)\n",
    "\n",
    "num_train = int(total * .8)\n",
    "num_val = int(total * .1)\n",
    "num_test = total - num_train - num_val\n",
    "\n",
    "# make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
    "\n",
    "train_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train)]\n",
    "val_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_train, num_val+num_train)]\n",
    "test_set = [(input_ids[i], attention_masks[i], labels[i]) for i in range(num_val + num_train, total)]\n",
    "\n",
    "train_text = [texts[i] for i in range(num_train)]\n",
    "val_text = [texts[i] for i in range(num_train, num_val+num_train)]\n",
    "test_text = [texts[i] for i in range(num_val + num_train, total)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCr006iTkqwM"
   },
   "source": [
    "Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPo640_ZlEPK",
    "outputId": "3cc0b13a-f7fb-4773-d82d-b37c9ac89bd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3lLdoW_le3M"
   },
   "source": [
    "# ACTION REQUIRED #\n",
    "\n",
    "Define your fine-tuning hyperparameters in the cell below (we have randomly picked some values to start with). We want you to experiment with different configurations to find the one that works best (i.e., highest accuracy) on your validation set. Feel free to also change pretrained models to others available in the HuggingFace library (you'll have to modify the cell above to do this). You might find papers on BERT fine-tuning stability (e.g., [Mosbach et al., ICLR 2021](https://openreview.net/pdf?id=nzpLWnVAyah)) to be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dd2JdC6IletV",
    "outputId": "29af1c88-d260-4fca-e7fb-15e8b6cb20d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd4fwn_el1ge"
   },
   "source": [
    "# Fine-tune your model\n",
    "Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_Mzr-kd5RaY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# function to get validation accuracy\n",
    "def get_validation_performance(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "      end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "      batch = val_set[i*batch_size:end_index]\n",
    "\n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device)\n",
    "\n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():\n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        outputs = model(b_input_ids,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the number of correctly labeled examples in batch\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "        num_correct = np.sum(pred_flat == labels_flat)\n",
    "        total_correct += num_correct\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_correct / len(val_set)\n",
    "    return avg_val_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTf_ipbjWNoV",
    "outputId": "0056f4a7-3643-4d2f-f67a-541667f3cd1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.710372805595398\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 2 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.698032796382904\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 3 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.719005286693573\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 4 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.713633954524994\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 5 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7040157914161682\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 6 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7388708591461182\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 7 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7366893291473389\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 8 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7219849824905396\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 9 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.741681694984436\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 10 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7000309228897095\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 11 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7216963171958923\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 12 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7055571675300598\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 13 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7076183557510376\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 14 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.6769856214523315\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 15 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.739535391330719\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 16 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7077912092208862\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 17 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7097353339195251\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 18 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.7081791758537292\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 19 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.6861714124679565\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "======== Epoch 20 / 20 ========\n",
      "Training...\n",
      "Total loss: 1.700326144695282\n",
      "Validation accuracy: 0.7631578947368421\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# training loop\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    num_batches = int(len(train_set)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "      end_index = min(batch_size * (i+1), len(train_set))\n",
    "\n",
    "      batch = train_set[i*batch_size:end_index]\n",
    "\n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device)\n",
    "\n",
    "      # Clear the previously calculated gradient\n",
    "      model.zero_grad()\n",
    "\n",
    "      # Perform a forward pass (evaluate the model on this training batch).\n",
    "      outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "      loss = outputs.loss\n",
    "      logits = outputs.logits\n",
    "\n",
    "      total_train_loss += loss.item()\n",
    "\n",
    "      # Perform a backward pass to calculate the gradients.\n",
    "      loss.backward()\n",
    "\n",
    "      # Update parameters and take a step using the computed gradient.\n",
    "      optimizer.step()\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set. Implement this function in the cell above.\n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    val_acc = get_validation_performance(val_set)\n",
    "    print(f\"Validation accuracy: {val_acc}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9DpRJE5mHkO"
   },
   "source": [
    "# Evaluate your model on the test set\n",
    "After you're satisfied with your hyperparameters (i.e., you're unable to achieve higher validation accuracy by modifying them further), it's time to evaluate your model on the test set! Run the below cell to compute test set accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msvZ78ii3cZZ",
    "outputId": "25951546-540b-4e4b-a86c-4ce55418d401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_validation_performance(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcMT5aih8xEb"
   },
   "source": [
    "## Question 2.1 (10 points):\n",
    "Congratulations! You've now gone through the entire fine-tuning process and created a model for your downstream task. Two more questions left :) First, describe your hyperparameter selection process in words. If you based your process on any research papers or websites, please reference them. Why do you think the hyperparameters you ended up choosing worked better than others? Also, is there a significant discrepancy between your test and validation accuracy? Why do you think this is the case?\n",
    "\n",
    "### *WRITE YOUR ANSWER HERE*\n",
    "\n",
    "First question:\n",
    "\n",
    "I tried many values for each of the hyperparameters, mostly learning rate, epochs and batch size.\n",
    "\n",
    "The BERT paper recommended either 32 or 64 for batch size. Aside from these values, I gave batch size the value of 256. However, sometimes Google Colab would send me error, telling me it has run out of memory. So, I degraded the batch size to 128. This amount is however, good and works well for me, so, I went with it.\n",
    "\n",
    "In next step, for epochs I tried values such as 10, 20, 30, 50, 66, and 80. The more I trained the model, the stable the results were. Meaning, increasing the number of epochs did not have any positive effect for me. The best value I came up with was 20. I compared the results when I trained the model for 20 and 30 epochs, and, between these two I could not distinguish anything, and sometimes the performance was the same. So, I chose 20 for epochs.\n",
    "\n",
    "At last, I tried multiple values such as 1e-3, 1e-5, 2e-3, 2e-5, 3e-5, 4e-5, 5e-5, 6e-5, 7e-5. Among these, only the values 5e-5 and 6e-5 worked really well and the loss was decreasing faster. When I used 6e-5 I got really different results for test set, from 53% to 82%. But with 5e-5, I got much more stable results. I do not understand why, and I searched small searches to understand the reason. Unfortunately, I could not find anything useful to explain as to why the model behaved the way it did.\n",
    "\n",
    "I tried only two values for epsilon: 1e-8 and 2e-8. With 2e-8, I got worse results. So, I did not experiment on this hyperparameter that much and preferred to leave it as it is.\n",
    "\n",
    "As to why I think the chosen hyperparameters worked for me, I have to say that I chose the number of epochs wisely. The more the model was being trained, the more stale or even worse, it performed. I preferred to use a wise number of epochs, so that the model would not fine-tune for wrong reasons and overfit my small dataset, therefore, leading to catastrophic forgetting of the model (as it was discussed in class). For learning rate, I went with the default value, because it was mostly stable and it performed a little bit better than other values. However, since, my dataset is small, I could have stayed with the 6e-5 value or even a little bit higher than 5e-5, if I had not seen conflicting results. Lastly, for batch size, I wanted to give the hyperparameter bigger value, since I have a small dataset and I could train the model on all of it at once (in fewer iterations inside each epoch), and also the model has trained on large batches. Larger values for batch size helped the model decrease its loss fast and this was reassuring for me to go higher than 128. However, since, Google Colab was unstable when I assigned the batch size to 256, I remained on 128. For epislon, I did not delve too much into experiments like other hyperparameters. However, I tried some values for it after reading about it and how it works or affects the training process. At the end, I preferred to choose the default value for this hyperparameter.\n",
    "\n",
    "As for second question that if there is any discrepancy between test and validation accuracy, I have to say that I sometimes noticed discrepancy in my many and multiple experiments. However, it was not that acute, and I told myself the small size of test-set and validation-set can be a major factor for this. However, for the results I have provided for you, there is actually no discrepancy between the values of accuracy for test-set and validation-set. Since, I sometimes saw discrepancy and sometimes did not, I can add another factor such as learning rate, and how it has affected the performance of the model while training.\n",
    "\n",
    "Overall, since, the reviews/comments in our dataset are diverse and the dataset is not overall imbalanced, I can be certain that if there was any discrepancy between the values of accuracy between these two sets, it can be attributed to how the model has learnt and performed on training-set.\n",
    "\n",
    "For this question, I also did some research and read some papers. The values I brought above can either be referenced to these papers, or be determined by sheer trial-and-error done by me. I tried and compared the results for many possible combinations of values for each of the hyperparameters. Therefore, I reached to the final values for the hyperparameters.\n",
    "\n",
    "Nevertheless, of the research papers I glanced at, I can name:\n",
    "\n",
    "* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "* [Large Batch Optimization for Deep Learning: Training BERT in 76 minutes](https://arxiv.org/abs/1904.00962)\n",
    "* [How to Fine-Tune BERT for Text Classification?](https://link.springer.com/chapter/10.1007/978-3-030-32381-3_16)\n",
    "* [How to Train BERT with an Academic Budget](https://arxiv.org/abs/2104.07705)\n",
    "* [Visualizing and Understanding the Effectiveness of BERT](https://arxiv.org/abs/1908.05620)\n",
    "* [A Robustly Optimized BERT Pre-training Approach with Post-training](https://link.springer.com/chapter/10.1007/978-3-030-84186-7_31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBbdMwt79fIs"
   },
   "source": [
    "## Question 2.2 (20 points):\n",
    "Finally, perform an *error analysis* on your model. This is good practice for your final project. Write some code in the below code cell to print out the text of up to five test set examples that your model gets **wrong**. If your model gets more than five test examples wrong, randomly choose five of them to analyze. If your model gets fewer than five examples wrong, please design five test examples that fool your model (i.e., *adversarial examples*). Then, in the following text cell, perform a qualitative analysis of these examples. See if you can figure out any reasons for errors that you observe, or if you have any informed guesses (e.g., common linguistic properties of these particular examples). Does this analysis suggest any possible future steps to improve your classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X72mumhI9WdR",
    "outputId": "2bafe4a5-bbfa-488d-d0e8-57c7a2ce5c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "داخل توضیحات نوشته زبان فارسی و انگلیسی ولی زیر نویس فارسی بود ای کاش دوبله فارسی اضافه بشه اوج بدبختیه که بازی سازندش ایرانیه ولی زبان فارسی نداره سازنده حداقل احترام برای مخاطبای فارسی زبان کشورش باید بزاره در کل خوب بود\n",
      "\n",
      "ویژگی های مثبت: 1-جنگل پویا:به خصوص تو منرحله ماسوله برف ها با کیفیت بودند(برف هاش با کیفیت بودن ولی مه اش با کیفیت تر بودند،انگار داشتم بازیsilent hillبازی میکرم{البته منsilent hillبازی نکردم بلکه فیلم کوتاهی از گیمپلی اش رو دیدم}) 2-صدا بعضی از شخضیت ها با کیفیت بودند3-شاید تیربارهای موجود تو بازی گرافیک با کیفیت ندارند اما صدا واقعا\" اکشن صدا می شود. بازی چندان خوبی نبود.اما تو مرحله یکی می دونه خیلی بد بود اصلا فانوس ها رو کجات گذاشتند که من بد از یکم ساعت تونستم پیدا بکنم. سایر ویژگی های منفی: 1-تیر می زنیم به دشمنان اصلا انگار جلیگه ضد گلوله پوشیدند. 2-اصلا تکلیف چیه،بعضی ها از فانوس هال رو باید نزدیک نزدیک بزنیم یا دور د ور بزنیم.و 3-نور پردازی نه چندان خوب در شب 4-شاتگان دو تیر یا همان تفنگ پدر انگار برای دکور با این تفنگ انگار داریم گلوله پلاستیکی به دشمن شلیک می کنیم هرچی تیر شاتگان(تفنگ پدر)به سمت دشمن شلیک می کردم فایذدهع که نداشت که هیچی حتی یکی دشمنانم تو بازی بتا خیال راحت داشت به سمت می یامد.5-دیر لود کردن یا دیر بالا آمدن گرافیک تفنگ ها:وقتی اسلحه عوض می کنم انگار تفنگ فراموش می کنه که گرافیک داره. بازی چندان نه خوب ولی تقریبا\" رضایت کننده،اگر نقد و بررسی دقیقی می خواهید می توانید تو سایت بازی نگار مطالع بکنی،تو سایت بازی نگار و گیمین می توان گیمپلی بازی رو تماشا بکنی(البته منظورم تو آپارت است)\n",
      "\n",
      "بازی بدی نیست ولی در مقابل شبان شانسی ندارع\n",
      "\n",
      "یک بازی عالی و خوب برای دوست داران تک تیراندازان نقاط قوت:۱-اکوسیستم به شدت واقعی با اینکه از زمان انتشار خیلی می گذره. ۲-هوش مصنوعی به نسبت خوب دشمنان ۳-تنوع نسبتا خوب راه های مختلف مخفی کاری ۴-تنوع خوب تجهیزات همراه کاراکتر تحت کنترل ۵-بیشتر کاتسین ها تماشایی هستند ۶-لگد خوب و نسبتا واقعگرایانه اسلحه های اسنایمر و سلاح کمری ۷-تنوع خیلی خوب درجه های سختی ۸-قابلیت پشتیبانی از بازی دسته ی XBOX360 و قابل تغییر تنظیمات آن نقاط ضعف:۱-انگار برای سایر سلاح ها اصلا گدی برای اونها تعریف نشده ۲-گرافیک نه چندان مدرن(در عوض اصلا افت فریمی ندارد) ۳-طراحی های یکم تکراری و مثل هم دشمنان تو بازی ۴-غیر فعال بودن بخش چند نفره(البته قابلیت LAN رو دارید،)\n",
      "\n",
      "سلام،بازی از نظر داستانی و معمایی که به حد کافی خوبه اما مشکلی که شرکت رساناشکوه در تمام بازیهای معماییش داره اینه که اصلا روی انیمیشن کاراکتراش کار نمیکنه و همیشه یک کاراکتر رو با انیمیشن مشابه و فقط چهره متفاوت وارد بازیهاش میکنه که خوب این ضعف قابل چشم پوشی به حساب نمیاد و آدم رو خسته میکنه لطفا روی حرکات دست و صورت کاراکترها بیشتر کارکنید تا قابل حمایت باشید.ممنون\n",
      "\n",
      "افتضاح بود. هزاران مشکل تو همه قسمتا داشت. رابط کاربری پر از باگ و گنگ، داستان بی معنی، معماهای بی معنی و گنگ، اشیا کاملا بی ربط تو همه جا واسه حل کردن و ...... اصلا توصیه نمیکنم. 100% وقت تلف کردنه.\n",
      "\n",
      "بلزی خوبیه.گرافیک خوب واستانداردی رو برای یه بازیه ماجرایی داره.ولی معماهای بازی اکثرا غیر منطقی و بیشتر روی ازمون و خطا کار شده.مخصوصا معمای جورچینش که فقط یه جای خالی واسه تکمیل شکل و بازی با اشکال داره اونم با وقت کم! که بیشتر یه بازیه سخته کارتیه تا معما و بیشتر مهارت میخاد تا تفکر.\n",
      "\n",
      "یه نظر کلی درباره بازی های ایرانی میدم خواهشا سازندگان بازی های ایرانی به این نکته توجه بکنن. لطفا بازیی که در ان از نوشته فارسی استفاده شده رو، نوشته هاش رو یذره بزرگ تر کنید یا یه استروک بهش بدید که بشه خوند و اصلا هم از فونت های فانتزی استفاده نکنید. چشمام کور شد تا بتونم نوشته های داخل بازی رو بخونم. اول بازی هم چقدر دنبال دکمه باز شدن کوله پشتی گشتم کاش اولش یه ریز راهنما میدادید. یه سری باگ های جزئی هم توی راه رفتنش داره مثلا بعضی وفتا از پله که میخواد بره بالا کاراکتر یخورده بزرگ و کوچیک میشه. در کل ارزش یک بار بازی کردن رو داره\n",
      "\n",
      "سلام بازی جذاب هست ولی چه فایده وقتی دوربین بازی رو به سمت عقب برمیگردونی لگ شدید میشه به علاوه این که باید کات سین هارو کامل تماشا کنی حتی اگه این هزارمین باری باشه که باختی و میخاد از اول بهت کات سین رو نشون بده راستی این که برای بازی های ایرانی بسته الحاقی نمیاد رو مخ هستش و اگه میشد بازی رو جان باز بزارید با قابلیت تعوض اسلحه و زره بهتر بود\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## YOUR ERROR ANALYSIS CODE HERE\n",
    "## print out up to 5 test set examples (or adversarial examples) that your model gets wrong\n",
    "\n",
    "def mis_classified_examples(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "      end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "      batch = val_set[i*batch_size:end_index]\n",
    "\n",
    "      if len(batch) == 0: continue\n",
    "\n",
    "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "      label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "      # Move tensors to the GPU\n",
    "      b_input_ids = input_id_tensors.to(device)\n",
    "      b_input_mask = input_mask_tensors.to(device)\n",
    "      b_labels = label_tensors.to(device)\n",
    "\n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():\n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        outputs = model(b_input_ids,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the number of correctly labeled examples in batch\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        labels_flat = label_ids.flatten()\n",
    "\n",
    "        indices = [i for i, (x, y) in enumerate(zip(pred_flat, labels_flat)) if x != y]\n",
    "\n",
    "    return indices\n",
    "\n",
    "indices = mis_classified_examples(test_set)\n",
    "\n",
    "for i in indices:\n",
    "    print(test_text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XyBdAup-e6Z"
   },
   "source": [
    "### *DESCRIBE YOUR QUALITATIVE ANALYSIS OF THE ABOVE EXAMPLES HERE*\n",
    "\n",
    "Since, our test-set did not have that many reviews/comments, and since, the accuracy of our fine-tuned model was a little bit better, I decided to print out all the reviews/comments the model got the label wrong, so that I could have a better understanding of the performance of the model.\n",
    "\n",
    "In some reviews/comments, the review/comment comprised of multiple sentences. Some sentences sounded negative, but the overall intent of the user was positive. In these cases, the model could not perform well. Or, the review/comment comprised of some positive sentences, but overall, the user has felt bad about the game. In these cases, which we can see above, the model could not perform very well and accurately label the review/comment. I can claim that the model has not been able to extract the true intent of those reviews/comments and has shown weak performance from itself.\n",
    "\n",
    "In other cases, the review/comment seems actually easy (like the third review/comment from above), however, the reason as to why the model has not been able to accurately label it, is baffling to me. Maybe the sentence which the user has claimed the game is not bad, made the model think that the review/comment is positive.\n",
    "\n",
    "Overall, I can conclude that the model is not strong enough to understand the true intent of some reviews/comments, when the reviews/comments comprise of multiple sentences that might be conflicting with one another. In these cases, no matter how many epochs I let the model be trained, it cannot truly understand why a specific review/comment has a specific label. For future work, I suggest using a stronger model, or a model which has had been trained on multiple tasks and bigger dataset in pre-training phase. In this approach, I can claim that the model can perform better. For example, if I feed the reviews/comments to ChatGPT or GPT-4, I would get much better results, even though I cannot fine-tune those models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szIkBDiQ_Mkv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Finished? Remember to upload the PDF file of this notebook and url of your colab and your three dataset files (annotator1.csv, annotator2.csv, and final_data.csv) to Elearn (elearn.ut.ac.ir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYqR5s9nzX9s"
   },
   "source": [
    "## AI Disclosure\n",
    "\n",
    "*   Did you use any AI assistance to complete this homework? If so, please also specify what AI you used.\n",
    "    * *No*\n",
    "\n",
    "\n",
    "---\n",
    "*(only complete the below questions if you answered yes above)*\n",
    "\n",
    "*   If you used a large language model to assist you, please paste *all* of the prompts that you used below. Add a separate bullet for each prompt, and specify which problem is associated with which prompt.\n",
    "    * *your response here*\n",
    "*   **Free response**: For each problem for which you used assistance, describe your overall experience with the AI. How helpful was it? Did it just directly give you a good answer, or did you have to edit it? Was its output ever obviously wrong or irrelevant? Did you use it to get the answer or check your own answer?\n",
    "    * *your response here*\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Heui1z3IjZh_",
    "935duWappc-o",
    "bcIMegO_uPRK",
    "Qd7Xq4SKzF5U"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01d1fe918573417ca15ffdf3464a9360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d500c622d6f4594a1d80889504d6d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01d1fe918573417ca15ffdf3464a9360",
      "placeholder": "​",
      "style": "IPY_MODEL_83705bfc34134a3ea0e825420bc6c7ad",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "107d352250ea4018892b3dfc29bf4ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "190c8e95a7844c8492729bbf0197be17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d4850d0f00a45a98c3f2ecedce94654": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37f67a74d0c0478c9c47a65b70afcc44",
      "placeholder": "​",
      "style": "IPY_MODEL_107d352250ea4018892b3dfc29bf4ac4",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "2659e1f1ef3442baa5beeb86b8027587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f66d9a518d724a998fb8435208cb4837",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_43d8d32e27f348f3bf941ea94ea3e91e",
      "value": 28
     }
    },
    "37f67a74d0c0478c9c47a65b70afcc44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40d5fc4582b14c16bfc1af217d77595d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d8d32e27f348f3bf941ea94ea3e91e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43e12cdf3c9b480baeea10403319ce86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae5224b5e173463892870ffc69cd2c58",
      "placeholder": "​",
      "style": "IPY_MODEL_8454ba6b1afc49df870acf75c24c9d1c",
      "value": " 232k/232k [00:00&lt;00:00, 3.39MB/s]"
     }
    },
    "44cc931cb4344e3fad48cb3fd7db8bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbfb65254be341a1809459aaaffec5f1",
      "placeholder": "​",
      "style": "IPY_MODEL_5768b842fd86457d854ac88ff334933d",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "47db893e385142b68a5ef615e6b1aa0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e0efdf992ff4db49d8964e1ac05d129": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51c65e5ca4924d97bdfb92e28436a538": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530458bd90844459899615a517070cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "53680c03cf86480184017b6b090f85df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47db893e385142b68a5ef615e6b1aa0f",
      "placeholder": "​",
      "style": "IPY_MODEL_b00b01e9b53c4993bd2cd232109b7ca2",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.36kB/s]"
     }
    },
    "5768b842fd86457d854ac88ff334933d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b1a53374cb445a89f6b7dd622d834d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61230637ed1b4fd98a494791416029a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c65e5ca4924d97bdfb92e28436a538",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d426ba3f665346dd8b67d62b856cde49",
      "value": 231508
     }
    },
    "6355e1a49a034b37a0dd3ebebb4b2ffd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d4850d0f00a45a98c3f2ecedce94654",
       "IPY_MODEL_6aff4307521d451193b7d9e10c0f3b4e",
       "IPY_MODEL_837d3915d27e4bca9c8d262981121780"
      ],
      "layout": "IPY_MODEL_5b1a53374cb445a89f6b7dd622d834d6"
     }
    },
    "6aff4307521d451193b7d9e10c0f3b4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb03dc01540e4e22972da416e07e539d",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_97c7028605234b979237a3c6487c1bc8",
      "value": 570
     }
    },
    "7039b328993b42449fd817ad078415d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71c7f61706094afd9feb2f7eef43fa53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72571fd7d911419e95de25d7cee605cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79460ad755494fa785bf176e6f0d6f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44cc931cb4344e3fad48cb3fd7db8bbe",
       "IPY_MODEL_2659e1f1ef3442baa5beeb86b8027587",
       "IPY_MODEL_53680c03cf86480184017b6b090f85df"
      ],
      "layout": "IPY_MODEL_7039b328993b42449fd817ad078415d2"
     }
    },
    "83705bfc34134a3ea0e825420bc6c7ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "837d3915d27e4bca9c8d262981121780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40d5fc4582b14c16bfc1af217d77595d",
      "placeholder": "​",
      "style": "IPY_MODEL_bd99d54bca6b44f99372221f1ace4115",
      "value": " 570/570 [00:00&lt;00:00, 29.2kB/s]"
     }
    },
    "8454ba6b1afc49df870acf75c24c9d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97c7028605234b979237a3c6487c1bc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9ae06fb985c84e5ea447e92da8ebb501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee2bf4dd8fa94dd5834ad815644bb6b6",
      "placeholder": "​",
      "style": "IPY_MODEL_4e0efdf992ff4db49d8964e1ac05d129",
      "value": " 466k/466k [00:00&lt;00:00, 9.18MB/s]"
     }
    },
    "ae5224b5e173463892870ffc69cd2c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b00b01e9b53c4993bd2cd232109b7ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6007f26921543f9be04c3654c949597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72571fd7d911419e95de25d7cee605cf",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_530458bd90844459899615a517070cb1",
      "value": 466062
     }
    },
    "b6ee7836a1ed45688c3090451b2711d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d500c622d6f4594a1d80889504d6d09",
       "IPY_MODEL_61230637ed1b4fd98a494791416029a9",
       "IPY_MODEL_43e12cdf3c9b480baeea10403319ce86"
      ],
      "layout": "IPY_MODEL_190c8e95a7844c8492729bbf0197be17"
     }
    },
    "bd99d54bca6b44f99372221f1ace4115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7a1fa1ca8324b33aede90a754c19d16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3d7c078b27b4704b218d59e161c85f9",
       "IPY_MODEL_b6007f26921543f9be04c3654c949597",
       "IPY_MODEL_9ae06fb985c84e5ea447e92da8ebb501"
      ],
      "layout": "IPY_MODEL_fc971c2cf8af4283a8ce330bf27cae75"
     }
    },
    "c908cbe920aa48e4bafc31da35f4f2cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d426ba3f665346dd8b67d62b856cde49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee2bf4dd8fa94dd5834ad815644bb6b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3d7c078b27b4704b218d59e161c85f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c908cbe920aa48e4bafc31da35f4f2cc",
      "placeholder": "​",
      "style": "IPY_MODEL_71c7f61706094afd9feb2f7eef43fa53",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "f66d9a518d724a998fb8435208cb4837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb03dc01540e4e22972da416e07e539d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbfb65254be341a1809459aaaffec5f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc971c2cf8af4283a8ce330bf27cae75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
